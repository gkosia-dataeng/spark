{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f570252c-8e1e-4180-a420-bf6ac7f9b2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7c1dcfae2d61:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Reading from sockets</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f4df041cac0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Reading from sockets\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.cores.max\", 4)\n",
    "    .config(\"spark.executor.cores\",2)\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5b2b40-9d9f-4087-9bda-31566fcdd0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\",False)\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\",False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1d31b8d-007a-4af8-9caa-dbf595c4a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "emp = spark.read.format(\"csv\").schema(emp_schema).option(\"header\", True).load(\"/home/jovyan/data/employee_records.csv\")\n",
    "\n",
    "\n",
    "dep_schema = \"department_id int, department_name string, description string, coty string, state string, country string\"\n",
    "dep = spark.read.format(\"csv\").schema(dep_schema).option(\"header\", True).load(\"/home/jovyan/data/department.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "725d42bc-4443-4420-84f3-2266480ce91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(4) SortMergeJoin [department_id#7], [department_id#16], LeftOuter\n",
      ":- *(1) Sort [department_id#7 ASC NULLS FIRST], false, 0\n",
      ":  +- Exchange hashpartitioning(department_id#7, 200), ENSURE_REQUIREMENTS, [id=#70]\n",
      ":     +- FileScan csv [first_name#0,last_name#1,job_title#2,dob#3,email#4,phone#5,salary#6,department_id#7] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/data/employee_records.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<first_name:string,last_name:string,job_title:string,dob:string,email:string,phone:string,s...\n",
      "+- *(3) Sort [department_id#16 ASC NULLS FIRST], false, 0\n",
      "   +- Exchange hashpartitioning(department_id#16, 200), ENSURE_REQUIREMENTS, [id=#82]\n",
      "      +- *(2) Filter isnotnull(department_id#16)\n",
      "         +- FileScan csv [department_id#16,department_name#17,description#18,coty#19,state#20,country#21] Batched: false, DataFilters: [isnotnull(department_id#16)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/data/department.csv], PartitionFilters: [], PushedFilters: [IsNotNull(department_id)], ReadSchema: struct<department_id:int,department_name:string,description:string,coty:string,state:string,count...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined = emp.join(dep, on=emp.department_id == dep.department_id, how=\"left_outer\")\n",
    "\n",
    "df_joined.write.format(\"noop\").mode(\"overwrite\").save()\n",
    "\n",
    "df_joined.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ed0132-786a-4627-adcc-2d1de4307fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|partition_id| count|\n",
      "+------------+------+\n",
      "|         103|100417|\n",
      "|         122| 99780|\n",
      "|          43| 99451|\n",
      "|         107| 99805|\n",
      "|          49| 99706|\n",
      "|          51|100248|\n",
      "|         102|100214|\n",
      "|          66|100210|\n",
      "|         174|100155|\n",
      "|          89|100014|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "    When we see  Spill (Memory) Spill (Disk) it means that some of the tasks process much data than other,and the data are not fit to memory because we have skew\n",
    "    Spill (Disk) is bad because the spark need to serialize them to put it to disk and den deserialize them again to process them\n",
    "'''\n",
    "from pyspark.sql.functions import spark_partition_id, count\n",
    "\n",
    "df_joined.withColumn(\"partition_id\", spark_partition_id()).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14a6eb78-f450-4a5a-a772-3b4fe8564515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Salting: add salt (random number on joining column to split fair the rowes between tasks)\n",
    "             after the join we remove the salt\n",
    "             \n",
    "             The big table will salted\n",
    "             The small table will cross joined with salt range df\n",
    "'''\n",
    "import random\n",
    "from pyspark.sql.functions import udf, concat, lit\n",
    "\n",
    "\n",
    "@udf\n",
    "def add_salt():\n",
    "    return random.randint(0,16)\n",
    "    \n",
    "    \n",
    "spark.conf.set(\"spark.shuffle.partitions\", 16)\n",
    "\n",
    "salt_df = spark.range(16)\n",
    "salt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdb241af-bba3-46e1-b529-d68d97b079c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+-----------------+\n",
      "|first_name| last_name|           job_title|       dob|               email|               phone|  salary|department_id|salted_department|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+-----------------+\n",
      "|   Richard|  Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|       (699)525-4827|512653.0|            8|             8_10|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|  (750)846-1602x7458|999836.0|            7|             7_11|\n",
      "|    Dennis|    Norman|Land/geomatics su...|1990-06-24| jturner@example.net|    873.820.0518x825|131900.0|           10|             10_2|\n",
      "|      John|    Monroe|        Retail buyer|1968-06-16|  erik33@example.net|    820-813-0557x624|485506.0|            1|              1_6|\n",
      "|  Michelle|   Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|       (705)900-5337|604738.0|            8|             8_15|\n",
      "|    Ashley|   Montoya|        Cartographer|1976-01-16|patrickalexandra@...|        211.440.5466|483339.0|            6|              6_0|\n",
      "| Nathaniel|     Smith|     Quality manager|1985-06-28|  lori44@example.net|        936-403-3179|419644.0|            7|              7_5|\n",
      "|     Faith|  Cummings|Industrial/produc...|1978-07-01| ygordon@example.org|       (889)246-5588|205939.0|            7|              7_2|\n",
      "|  Margaret|    Sutton|Administrator, ed...|1975-08-16| diana44@example.net|001-647-530-5036x...|671167.0|            8|              8_2|\n",
      "|      Mary|    Sutton|   Freight forwarder|1979-12-28|  ryan36@example.com|   422.562.7254x3159|993829.0|            7|              7_9|\n",
      "|      Jake|      King|       Lexicographer|1994-07-11|monica93@example.org|+1-535-652-9715x6...|702101.0|            4|             4_14|\n",
      "|   Heather|     Haley|         Music tutor|1981-06-01|stephanie65@examp...|   (652)815-7973x298|570960.0|            6|              6_2|\n",
      "|    Thomas|    Thomas|Chartered managem...|2001-07-17|pwilliams@example...|001-245-848-0028x...|339441.0|            6|              6_9|\n",
      "|   Leonard|   Carlson|       Art therapist|1990-10-18|gabrielmurray@exa...|          9247590563|469728.0|            8|             8_14|\n",
      "|      Mark|      Wood|   Market researcher|1963-10-13|nicholas76@exampl...|   311.439.1606x3342|582291.0|            4|             4_12|\n",
      "|    Tracey|Washington|Travel agency man...|1986-05-07|  mark07@example.com|    001-912-206-6456|146456.0|            4|              4_1|\n",
      "|   Rachael| Rodriguez|         Media buyer|1966-12-02|griffinmary@examp...| +1-791-344-7586x548|544732.0|            1|             1_13|\n",
      "|      Tara|       Liu|   Financial adviser|1998-10-12|alexandraobrien@e...|        216.696.6061|399503.0|            3|              3_6|\n",
      "|       Ana|    Joseph|      Retail manager|1995-01-10|  rmorse@example.org|  (726)363-7526x9965|761988.0|           10|             10_9|\n",
      "|   Richard|      Hall|Engineer, civil (...|1967-03-02|brandoncardenas@e...| (964)451-9007x22496|660659.0|            4|              4_1|\n",
      "+----------+----------+--------------------+----------+--------------------+--------------------+--------+-------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salted_employ = emp.withColumn(\"salted_department\", concat(\"department_id\", lit(\"_\"), add_salt()))\n",
    "salted_employ.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a163bade-db24-4451-a554-9581fb0b5d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+--------------------+-----+-------------------+---+-----------------+\n",
      "|department_id|     department_name|         description|                coty|state|            country| id|salted_department|\n",
      "+-------------+--------------------+--------------------+--------------------+-----+-------------------+---+-----------------+\n",
      "|            1|         Bryan-James|Optimized disinte...|        Melissaburgh|   FM|Trinidad and Tobago|  0|              1_0|\n",
      "|            2|Smith, Craig and ...|Digitized empower...|          Morrisside|   DE|          Sri Lanka|  0|              2_0|\n",
      "|            3|Pittman, Hess and...|Multi-channeled c...|         North David|   SC|       Turkmenistan|  0|              3_0|\n",
      "|            4|Smith, Snyder and...|Reactive neutral ...|       Lake Jennifer|   TX|         Madagascar|  0|              4_0|\n",
      "|            5|          Hardin Inc|Re-contextualized...|           Hayestown|   WA|               Fiji|  0|              5_0|\n",
      "|            6|         Sanders LLC|Innovative multim...|         Phamchester|   TN|         Micronesia|  0|              6_0|\n",
      "|            7|         Ward-Gordon|Progressive logis...|Lake Jeremiahborough|   WY|            Belgium|  0|              7_0|\n",
      "|            8|          Parker PLC|Assimilated multi...|         Barnettside|   AL|   Marshall Islands|  0|              8_0|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|         Marychester|   MN|              Italy|  0|              9_0|\n",
      "|           10|      Delgado-Keller|User-centric regi...|         Lake Ashley|   MD|              Qatar|  0|             10_0|\n",
      "|            1|         Bryan-James|Optimized disinte...|        Melissaburgh|   FM|Trinidad and Tobago|  1|              1_1|\n",
      "|            2|Smith, Craig and ...|Digitized empower...|          Morrisside|   DE|          Sri Lanka|  1|              2_1|\n",
      "|            3|Pittman, Hess and...|Multi-channeled c...|         North David|   SC|       Turkmenistan|  1|              3_1|\n",
      "|            4|Smith, Snyder and...|Reactive neutral ...|       Lake Jennifer|   TX|         Madagascar|  1|              4_1|\n",
      "|            5|          Hardin Inc|Re-contextualized...|           Hayestown|   WA|               Fiji|  1|              5_1|\n",
      "|            6|         Sanders LLC|Innovative multim...|         Phamchester|   TN|         Micronesia|  1|              6_1|\n",
      "|            7|         Ward-Gordon|Progressive logis...|Lake Jeremiahborough|   WY|            Belgium|  1|              7_1|\n",
      "|            8|          Parker PLC|Assimilated multi...|         Barnettside|   AL|   Marshall Islands|  1|              8_1|\n",
      "|            9|Mcmahon, Terrell ...|De-engineered hig...|         Marychester|   MN|              Italy|  1|              9_1|\n",
      "|           10|      Delgado-Keller|User-centric regi...|         Lake Ashley|   MD|              Qatar|  1|             10_1|\n",
      "+-------------+--------------------+--------------------+--------------------+-----+-------------------+---+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salted_dep = dep.join(salt_df, how='cross').withColumn(\"salted_department\", concat(\"department_id\", lit(\"_\"), \"id\"))\n",
    "salted_dep.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25d19277-c79d-439f-a66f-471a2022c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "salted_join = salted_employ.join(salted_dep, on=salted_employ.salted_department == salted_dep.salted_department, how=\"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3ee7ae2-5f04-483a-a213-a437a44f63d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|partition_id|count|\n",
      "+------------+-----+\n",
      "|          31|11965|\n",
      "|         137|11861|\n",
      "|         101|11920|\n",
      "|         126|11799|\n",
      "|          81|11770|\n",
      "|         183| 5860|\n",
      "|          76| 5926|\n",
      "|          26| 5896|\n",
      "|          27|11760|\n",
      "|         192| 5733|\n",
      "|          91| 5788|\n",
      "|         122|11974|\n",
      "|          93|23462|\n",
      "|          47| 5910|\n",
      "|         152| 5807|\n",
      "|         185| 5771|\n",
      "|         146| 5961|\n",
      "|          52| 5770|\n",
      "|         182| 5901|\n",
      "|         168| 5837|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "salted_join.withColumn(\"partition_id\", spark_partition_id()).groupBy(\"partition_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cab5ed0-1aa0-4032-9127-20e7f9025ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "salted_join.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea47821-8365-4a63-8ee6-d7a4b33fff2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
