{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c752dab2-b10a-4b83-b4a7-6ab2dadeddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://a34071f56a07:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Reading from sockets</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3c7054e740>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Reading from sockets\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.executor.memory\",\"512M\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2139e442-3cc9-46d3-9f18-06de5c76d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(\"/home/jovyan/data/employee_records.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca67bb29-90f9-464e-98b9-ba2d7622218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    I want to transform department_id to department name\n",
    "        1. Option 1 is to join df with department dataframe, but join will trigger a shuffle\n",
    "        2. Option 2 is to create a map with ids and names in a variable and transform it with map or udf function\n",
    "                    option 2 it will deseirialize and serialize the data in order to execute outside of spark\n",
    "        \n",
    "'''\n",
    "\n",
    "# Option 3 is to use a broadcast variable\n",
    "# Broadcast variables are send to each executor can be used in spark\n",
    "\n",
    "dep_names = {\n",
    "    1: \"Dept 1\",\n",
    "    2: \"Dept 2\",\n",
    "    3: \"Dept 3\",\n",
    "    4: \"Dept 4\",\n",
    "    5: \"Dept 5\",\n",
    "    6: \"Dept 6\",\n",
    "    7: \"Dept 7\",\n",
    "    8: \"Dept 8\",\n",
    "    9: \"Dept 9\",\n",
    "    10: \"Dept 10\"\n",
    "}\n",
    "\n",
    "broad_dep_names = spark.sparkContext.broadcast(dep_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b224d385-573a-49b0-8ce8-e5e861683945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Dept 1',\n",
       " 2: 'Dept 2',\n",
       " 3: 'Dept 3',\n",
       " 4: 'Dept 4',\n",
       " 5: 'Dept 5',\n",
       " 6: 'Dept 6',\n",
       " 7: 'Dept 7',\n",
       " 8: 'Dept 8',\n",
       " 9: 'Dept 9',\n",
       " 10: 'Dept 10'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pyspark.broadcast.Broadcast"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(broad_dep_names.value)\n",
    "type(broad_dep_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d0f7b3-b763-4bb7-a14f-8c37277bcab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------------------+-------------------+--------------------+--------------------+------+-------------+---------+\n",
      "|first_name| last_name|           job_title|                dob|               email|               phone|salary|department_id|dept_name|\n",
      "+----------+----------+--------------------+-------------------+--------------------+--------------------+------+-------------+---------+\n",
      "|   Richard|  Morrison|Public relations ...|1973-05-05 00:00:00|melissagarcia@exa...|       (699)525-4827|512653|            8|   Dept 8|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|1974-04-25 00:00:00|   llara@example.net|  (750)846-1602x7458|999836|            7|   Dept 7|\n",
      "|    Dennis|    Norman|Land/geomatics su...|1990-06-24 00:00:00| jturner@example.net|    873.820.0518x825|131900|           10|  Dept 10|\n",
      "|      John|    Monroe|        Retail buyer|1968-06-16 00:00:00|  erik33@example.net|    820-813-0557x624|485506|            1|   Dept 1|\n",
      "|  Michelle|   Elliott|      Air cabin crew|1975-03-31 00:00:00|tiffanyjohnston@e...|       (705)900-5337|604738|            8|   Dept 8|\n",
      "|    Ashley|   Montoya|        Cartographer|1976-01-16 00:00:00|patrickalexandra@...|        211.440.5466|483339|            6|   Dept 6|\n",
      "| Nathaniel|     Smith|     Quality manager|1985-06-28 00:00:00|  lori44@example.net|        936-403-3179|419644|            7|   Dept 7|\n",
      "|     Faith|  Cummings|Industrial/produc...|1978-07-01 00:00:00| ygordon@example.org|       (889)246-5588|205939|            7|   Dept 7|\n",
      "|  Margaret|    Sutton|Administrator, ed...|1975-08-16 00:00:00| diana44@example.net|001-647-530-5036x...|671167|            8|   Dept 8|\n",
      "|      Mary|    Sutton|   Freight forwarder|1979-12-28 00:00:00|  ryan36@example.com|   422.562.7254x3159|993829|            7|   Dept 7|\n",
      "|      Jake|      King|       Lexicographer|1994-07-11 00:00:00|monica93@example.org|+1-535-652-9715x6...|702101|            4|   Dept 4|\n",
      "|   Heather|     Haley|         Music tutor|1981-06-01 00:00:00|stephanie65@examp...|   (652)815-7973x298|570960|            6|   Dept 6|\n",
      "|    Thomas|    Thomas|Chartered managem...|2001-07-17 00:00:00|pwilliams@example...|001-245-848-0028x...|339441|            6|   Dept 6|\n",
      "|   Leonard|   Carlson|       Art therapist|1990-10-18 00:00:00|gabrielmurray@exa...|          9247590563|469728|            8|   Dept 8|\n",
      "|      Mark|      Wood|   Market researcher|1963-10-13 00:00:00|nicholas76@exampl...|   311.439.1606x3342|582291|            4|   Dept 4|\n",
      "|    Tracey|Washington|Travel agency man...|1986-05-07 00:00:00|  mark07@example.com|    001-912-206-6456|146456|            4|   Dept 4|\n",
      "|   Rachael| Rodriguez|         Media buyer|1966-12-02 00:00:00|griffinmary@examp...| +1-791-344-7586x548|544732|            1|   Dept 1|\n",
      "|      Tara|       Liu|   Financial adviser|1998-10-12 00:00:00|alexandraobrien@e...|        216.696.6061|399503|            3|   Dept 3|\n",
      "|       Ana|    Joseph|      Retail manager|1995-01-10 00:00:00|  rmorse@example.org|  (726)363-7526x9965|761988|           10|  Dept 10|\n",
      "|   Richard|      Hall|Engineer, civil (...|1967-03-02 00:00:00|brandoncardenas@e...| (964)451-9007x22496|660659|            4|   Dept 4|\n",
      "+----------+----------+--------------------+-------------------+--------------------+--------------------+------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf,col\n",
    "\n",
    "# we can use broadcast variables in udfs\n",
    "\n",
    "@udf\n",
    "def get_dep_names(dept_id):\n",
    "    return broad_dep_names.value.get(dept_id)\n",
    "    \n",
    "    \n",
    "df.withColumn(\"dept_name\", get_dep_names(col(\"department_id\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b4bd0c-632c-41bd-a609-564fe841bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------------------+\n",
      "|department_id|CAST(sum(salary) AS BIGINT)|\n",
      "+-------------+---------------------------+\n",
      "|            6|                50294510721|\n",
      "+-------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Problem: Calculate the sum of salary of all employees for department 6\n",
    "             For this problem each executor will calculate the sum of its own data and then the results should send to one executor to calculate the total\n",
    "             \n",
    "'''\n",
    "\n",
    "# Using accumulators each executor will submit the result to the accumulator and we will avoid the shuffle\n",
    "\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "# this solution will involve shuffle of each executor result\n",
    "df.where(\"department_id == 6\").groupBy(\"department_id\").agg(sum(\"salary\").cast(\"long\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca7afc66-4341-4f49-93e7-96b40a052cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50294510721"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using accumulators\n",
    "\n",
    "# initialize the accumulator\n",
    "dep_salary_accum = spark.sparkContext.accumulator(0)\n",
    "\n",
    "# define the function that will operate for each row\n",
    "def calculate_dep_salary(department, salary):\n",
    "    if department == 6:\n",
    "        dep_salary_accum.add(salary) \n",
    "\n",
    "# execute the function in distributed way for each row        \n",
    "df.foreach(lambda row: calculate_dep_salary(row.department_id, row.salary))\n",
    "\n",
    "\n",
    "\n",
    "dep_salary_accum.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc7c4c-2efc-441c-ae0e-f7aaf6d5f068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
