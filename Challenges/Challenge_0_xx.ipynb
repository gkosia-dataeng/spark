{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604ff057-0b99-403d-9ea5-c5b7792f1e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3b3979213cec:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>challenge 0 - </code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f6656683e50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.session import get_spark_session\n",
    "\n",
    "spark  = get_spark_session(\"challenge 0 - \")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b29a3c-66e0-41c9-9a5b-c66c200ed1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+-----+\n",
      "|   Name|Value|index|\n",
      "+-------+-----+-----+\n",
      "|  Alice|    1|    1|\n",
      "|    Bob|    2|    2|\n",
      "|Charlie|    3|    3|\n",
      "+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create auto increment column\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, monotonically_increasing_id\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "(\"Alice\", 1),\n",
    "(\"Bob\", 2),\n",
    "(\"Charlie\", 3),\n",
    "], [\"Name\", \"Value\"])\n",
    "\n",
    "\n",
    "wind = Window.orderBy(monotonically_increasing_id())\n",
    "\n",
    "df.withColumn(\"index\", row_number().over(wind)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c65bd9e-1447-47f5-9b88-6802c1967a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "|   d|   4|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists to dataframe\n",
    "list1 = [\"a\", \"b\", \"c\", \"d\"]\n",
    "list2 = [1, 2, 3, 4]\n",
    "\n",
    "rdd_from_list = spark.sparkContext.parallelize(list(zip(list1, list2)))\n",
    "df_from_list = rdd_from_list.toDF([\"col1\", \"col2\"])\n",
    "df_from_list.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5ff242-0da2-4b88-b349-9415308b21a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n",
      "[1, 2, 3, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# Get list of A does not exists in B\n",
    "list_A = [1, 2, 3, 4, 5]\n",
    "list_B = [4, 5, 6, 7, 8]\n",
    "\n",
    "ls_a = spark.sparkContext.parallelize(list_A)\n",
    "ls_b = spark.sparkContext.parallelize(list_B)\n",
    "\n",
    "'''\n",
    "    subtract: exists in A but not in A \n",
    "    union: all elements\n",
    "\n",
    "    collect: convert the rdd to list, or dataframe to Array[Row]  and return it to driver\n",
    "'''\n",
    "\n",
    "# in A not in B\n",
    "diff = ls_a.subtract(ls_b).collect()\n",
    "print(diff)\n",
    "\n",
    "\n",
    "# in A not in B or in B not in A\n",
    "not_in_B = ls_a.subtract(ls_b)\n",
    "not_in_A = ls_b.subtract(ls_a)\n",
    "\n",
    "\n",
    "print(not_in_B.union(not_in_A).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccacb639-d4b2-4cc8-a643-05388a87c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 20.0, 30.0, 50.0, 86.0]\n"
     ]
    }
   ],
   "source": [
    "# quantiles\n",
    "\n",
    "data = [(\"A\", 10), (\"B\", 20), (\"C\", 30), (\"D\", 40), (\"E\", 50), (\"F\", 15), (\"G\", 28), (\"H\", 54), (\"I\", 41), (\"J\", 86)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "\n",
    "# column, ntiles needed, error if 0 exact quantiles (expensive)\n",
    "quantiles = df.approxQuantile(\"Age\", [0.0, 0.25, 0.5, 0.75, 1.0], 0.01)\n",
    "\n",
    "print(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c796e754-1a93-4c6f-9003-44e9b3679675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "|name|freq|\n",
      "+----+----+\n",
      "|   a|   2|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# frequency\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "data = [\n",
    "    Row(name=\"a\", ),\n",
    "    Row(name=\"b\", ),\n",
    "    Row(name=\"b\", ),\n",
    "    Row(name=\"a\", ),\n",
    "    Row(name=\"c\", ),\n",
    "    Row(name=\"c\", ),\n",
    "    Row(name=\"c\", ),\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data)\n",
    "df.groupBy(\"name\").agg(count(\"name\").alias(\"freq\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f19b9-0173-47fa-b30a-6ddae64e7c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
